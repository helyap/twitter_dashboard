{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint_search\n",
    "\n",
    "inp = input(\"Do you already have a tweets dataset to upload (y/n)? If no, let's start scrapping!\")\n",
    "if inp == 'y':\n",
    "    file_path = input('Please enter the path to your existing tweets data file (.json file at local)')\n",
    "    keyword = input('What is your tweets data about? (Enter the keyword of the topic)')\n",
    "    tweets_list = json.load(open(file_path))\n",
    "    tweets_list = list(tweets_list.values())\n",
    "else:\n",
    "    keyword = input('What is the topic that you are interested in?')\n",
    "    before_time = input('What is the time window of your tweets (before yyyy-mm-dd)?')\n",
    "    after_time = input('What is the time window of your tweets (after yyyy-mm-dd)?')\n",
    "    num_tweets = input('How many tweets do you want?')\n",
    "    tweets_list, keyword = twint_search.search_tweet({'keyword': keyword, 'since': after_time, 'until': before_time, 'limit': num_tweets}, from_ui=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import dataset\n",
    "\n",
    "sqs = boto3.client('sqs')\n",
    "aws_lambda = boto3.client('lambda')\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(RoleName='LabRole')\n",
    "s3 = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "rds = boto3.client('rds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '6JAQD1QFFBNB1BVS',\n",
       "  'HostId': 'rdpZxFbEtovSI4CDD3jFjFx6GoXbLn98mgrfnJQr9Aprogt64926NCAdt/w6JMmHy5aN37J2SbE=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'rdpZxFbEtovSI4CDD3jFjFx6GoXbLn98mgrfnJQr9Aprogt64926NCAdt/w6JMmHy5aN37J2SbE=',\n",
       "   'x-amz-request-id': '6JAQD1QFFBNB1BVS',\n",
       "   'date': 'Fri, 03 Jun 2022 19:15:27 GMT',\n",
       "   'location': '/raw-tweet-bucket',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Location': '/raw-tweet-bucket'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create S3 bucket to store raw JSON data\n",
    "s3.create_bucket(Bucket='raw-tweet-bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relational-db is available at relational-db.ccps3ediik0q.us-east-1.rds.amazonaws.com on Port 3306\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = rds.create_db_instance(\n",
    "        DBInstanceIdentifier='relational-db',\n",
    "        DBName='twitter_sentiment',\n",
    "        MasterUsername='username',\n",
    "        MasterUserPassword='password',\n",
    "        DBInstanceClass='db.t2.micro',\n",
    "        Engine='MySQL',\n",
    "        AllocatedStorage=5\n",
    "    )\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Wait until DB is available to continue\n",
    "rds.get_waiter('db_instance_available').wait(DBInstanceIdentifier='relational-db')\n",
    "\n",
    "# Describe where DB is available and on what port\n",
    "db = rds.describe_db_instances()['DBInstances'][0]\n",
    "ENDPOINT = db['Endpoint']['Address']\n",
    "PORT = db['Endpoint']['Port']\n",
    "DBID = db['DBInstanceIdentifier']\n",
    "\n",
    "print(DBID,\n",
    "      \"is available at\", ENDPOINT,\n",
    "      \"on Port\", PORT,\n",
    "     )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permissions already adjusted.\n"
     ]
    }
   ],
   "source": [
    "# Get Name of Security Group\n",
    "SGNAME = db['VpcSecurityGroups'][0]['VpcSecurityGroupId']\n",
    "\n",
    "# Adjust Permissions for that security group so that we can access it on Port 3306\n",
    "# If already SG is already adjusted, print this out\n",
    "try:\n",
    "    ec2 = boto3.client('ec2')\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "            GroupId=SGNAME,\n",
    "            IpPermissions=[\n",
    "                {'IpProtocol': 'tcp',\n",
    "                 'FromPort': PORT,\n",
    "                 'ToPort': PORT,\n",
    "                 'IpRanges': [{'CidrIp': '0.0.0.0/0'}]}\n",
    "            ]\n",
    "    )\n",
    "except ec2.exceptions.ClientError as e:\n",
    "    if e.response[\"Error\"][\"Code\"] == 'InvalidPermission.Duplicate':\n",
    "        print(\"Permissions already adjusted.\")\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to RDS\n",
    "db_url = 'mysql+mysqlconnector://{}:{}@{}:{}/twitter_sentiment'.format('username', 'password', ENDPOINT, PORT)\n",
    "db = dataset.connect(db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('twitter_sentiment_deployment_package.zip', 'rb') as f:\n",
    "    lambda_zip = f.read()\n",
    "\n",
    "try:\n",
    "    # If function hasn't yet been created, create it\n",
    "    response = aws_lambda.create_function(\n",
    "        FunctionName='twitter_sentiment',\n",
    "        Runtime='python3.9',\n",
    "        Role=role['Role']['Arn'],\n",
    "        Handler='lambda_function.lambda_handler',\n",
    "        Code=dict(ZipFile=lambda_zip),\n",
    "        Timeout=100\n",
    "    )\n",
    "except aws_lambda.exceptions.ResourceConflictException:\n",
    "    # If function already exists, update it based on zip\n",
    "    # file contents\n",
    "    response = aws_lambda.update_function_code(\n",
    "    FunctionName='twitter_sentiment',\n",
    "    ZipFile=lambda_zip\n",
    "    )\n",
    "\n",
    "lambda_arn = response['FunctionArn']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create step function\n",
    "!python sfn_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_client = boto3.client('lambda')\n",
    "sfn = boto3.client('stepfunctions')\n",
    "\n",
    "def send_request(tweet_data, keyword):\n",
    "    raw_bucket_name = f'{keyword}-bucket'\n",
    "    tweet_batches = [{'batch': []} for i in range(10)]\n",
    "    batch_size = int(len(response)/10)\n",
    "    remaining = len(response)%10\n",
    "    batch_num = 0\n",
    "\n",
    "    for r in tweet_data:\n",
    "\n",
    "        tweet = {\n",
    "            'tweet_id': r['id'],\n",
    "            'datestamp': r['date'],\n",
    "            'timezone': r['timezone'],\n",
    "            'user_id': r['user_id'],\n",
    "            'num_retweets': r['nretweets'],\n",
    "            'num_likes': r['nlikes'],\n",
    "            'in_reply_to': r['user_rt_id'],\n",
    "            'text': r['tweet']\n",
    "        }\n",
    "\n",
    "        tweet_batches[batch_num]['batch'].append(tweet)\n",
    "        if len(tweet_batches[batch_num]['batch']) == batch_size:\n",
    "            if remaining > 0:\n",
    "                remaining -=1 \n",
    "                continue\n",
    "            batch_num += 1\n",
    "\n",
    "    data_files = [{'batch': []} for _ in range(10)]\n",
    "\n",
    "    for batch_id in range(10):\n",
    "        batch = tweet_batches[batch_id]\n",
    "        raw_file_name = f\"{keyword}_batch_{batch_id}.json\"\n",
    "        with open('/tmp/' + raw_file_name, \"w\") as outfile:\n",
    "            json.dump(batch, outfile)\n",
    "        s3.upload_file('/tmp/' + raw_file_name, raw_bucket_name, raw_file_name)\n",
    "        data_files[batch_id]['batch'] = [raw_bucket_name, raw_file_name]\n",
    "    \n",
    "\n",
    "    # step function for activating 10 lambda workers\n",
    "    response = sfn.list_state_machines()\n",
    "    state_machine_arn = [sm['stateMachineArn'] \n",
    "                        for sm in response['stateMachines'] \n",
    "                        if sm['name'] == 'twitter_sm'][0]\n",
    "\n",
    "    response = sfn.start_sync_execution(\n",
    "        stateMachineArn=state_machine_arn,\n",
    "        name='sentiment',\n",
    "        input=json.dumps(data_files)\n",
    "    )\n",
    "                                \n",
    "    return response['ResponseMetadata']['HTTPStatusCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send_request(tweets_list, keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'tweet_id',\n",
       " 'sentiment',\n",
       " 'sentiment_score',\n",
       " 'timestamp',\n",
       " 'user_id',\n",
       " 'num_retweets',\n",
       " 'num_likes',\n",
       " 'in_reply_to',\n",
       " 'text']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['tweets_table'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dump rds to json\n",
    "# all_data = db['tweets_table'].all()\n",
    "# all_data = [data for data in all_data]\n",
    "# with open('rds.json', \"w\") as outfile:\n",
    "#     json.dump(all_data, outfile, default=str)\n",
    "# json.load(open('rds.json'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
